{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from scipy.io import loadmat\n",
    "import json\n",
    "import numpy as np\n",
    "import random"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_idxs = loadmat('PR_data/cuhk03_new_protocol_config_labeled.mat')['train_idx'].flatten()-1\n",
    "query_idxs = loadmat('PR_data/cuhk03_new_protocol_config_labeled.mat')['query_idx'].flatten()-1\n",
    "gallery_idxs = loadmat('PR_data/cuhk03_new_protocol_config_labeled.mat')['gallery_idx'].flatten()-1\n",
    "labels = loadmat('PR_data/cuhk03_new_protocol_config_labeled.mat')['labels'].flatten()\n",
    "camId = loadmat('PR_data/cuhk03_new_protocol_config_labeled.mat')['camId'].flatten()\n",
    "filelist = loadmat('PR_data/cuhk03_new_protocol_config_labeled.mat')['filelist'].flatten()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('PR_data/feature_data.json','r') as f:\n",
    "    features = json.load(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "features = np.array(features) # rows: pictures, columns: features (one row contains one image)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(7368, 2048)\n",
      "(7368,)\n",
      "(1400, 2048)\n",
      "(1400,)\n",
      "(5328, 2048)\n",
      "(5328,)\n"
     ]
    }
   ],
   "source": [
    "train_feat = features[train_idxs,:]\n",
    "train_labels = labels[train_idxs]\n",
    "print(train_feat.shape)\n",
    "print(train_labels.shape)\n",
    "\n",
    "query_feat = features[query_idxs,:]\n",
    "query_labels = labels[query_idxs]\n",
    "print(query_feat.shape)\n",
    "print(query_labels.shape)\n",
    "\n",
    "gallery_feat = features[gallery_idxs,:]\n",
    "gallery_labels = labels[gallery_idxs]\n",
    "print(gallery_feat.shape)\n",
    "print(gallery_labels.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1149  484  293  363  315 1374 1306 1211 1045  844  248 1079  512   85\n",
      "  561  549 1245  204  155  126  589  848 1391 1455  642  633  868 1302\n",
      " 1269 1212 1085  414 1071  945  403  811  274 1345 1194  986 1034   57\n",
      " 1191 1180  576  568 1177   71  611  534  495 1104  808   46 1192 1141\n",
      "  283  502  787 1129  516  480 1453 1287  943  668   23  527  428   20\n",
      "  456  966 1284  243  785  108  538  389 1039  411  961 1053  323  226\n",
      " 1427  774 1084   53 1442  268  917 1246  507  368  579  500 1381  470\n",
      "   49 1462] (100,)\n",
      "966 (7368,)\n",
      "6402 (7368,)\n",
      "(6402, 2048) (6402,)\n",
      "(966, 2048) (966,)\n",
      "(767,) (667,) (100,)\n"
     ]
    }
   ],
   "source": [
    "unique_id_train = np.unique(train_labels)\n",
    "unique_id_val = unique_id_train[np.array(random.sample(range(1,unique_id_train.shape[0]-1),100))]\n",
    "print(unique_id_val, unique_id_val.shape)\n",
    "bool_idx_val = np.isin(train_labels, unique_id_val)\n",
    "bool_idx_train_noval = np.isin(train_labels, unique_id_val, invert=True)\n",
    "print(np.sum(bool_idx_val), bool_idx_val.shape)\n",
    "print(np.sum(bool_idx_train_noval), bool_idx_train_noval.shape)\n",
    "\n",
    "train_noval_feat = train_feat[bool_idx_train_noval,:]\n",
    "train_noval_labels = train_labels[bool_idx_train_noval]\n",
    "\n",
    "val_feat = train_feat[bool_idx_val,:]\n",
    "val_labels = train_labels[bool_idx_val]\n",
    "\n",
    "print(train_noval_feat.shape, train_noval_labels.shape)\n",
    "print(val_feat.shape, val_labels.shape)\n",
    "\n",
    "print(unique_id_train.shape, np.unique(train_noval_labels).shape, np.unique(val_labels).shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.savetxt('train_feat.gzip', train_feat)\n",
    "np.savetxt('train_labels.gzip', train_labels)\n",
    "np.savetxt('query_feat.gzip', query_feat)\n",
    "np.savetxt('query_labels.gzip', query_labels)\n",
    "np.savetxt('gallery_feat.gzip', gallery_feat)\n",
    "np.savetxt('gallery_labels.gzip', gallery_labels)\n",
    "np.savetxt('val_feat.gzip', val_feat)\n",
    "np.savetxt('val_labels.gzip', val_labels)\n",
    "np.savetxt('train_noval_feat.gzip', train_noval_feat)\n",
    "np.savetxt('train_noval_labels.gzip', train_noval_labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1467,)\n"
     ]
    }
   ],
   "source": [
    "print(np.unique(labels).shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
